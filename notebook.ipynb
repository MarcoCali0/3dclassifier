{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Training device: cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from modelnetvoxel_dataset import ModelNetDatasetVoxel\n",
    "from cnn_model import Simple3DCNN\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "DATA_DIR = \"ModelNet10\"\n",
    "SAVE_DIR = \"ModelNet10Voxel\"\n",
    "\n",
    "num_classes = 10\n",
    "grid_size = 32\n",
    "object_size = 24\n",
    "pitch_rescale = 1.0\n",
    "no_of_rotations = 1\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = ModelNetDatasetVoxel(SAVE_DIR, train=True)\n",
    "test_dataset = ModelNetDatasetVoxel(SAVE_DIR, train=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Simple3DCNN                              --                        --\n",
      "├─Conv3d: 1-1                            [64, 16, 32, 32, 32]      448\n",
      "├─MaxPool3d: 1-2                         [64, 16, 16, 16, 16]      --\n",
      "├─Conv3d: 1-3                            [64, 32, 16, 16, 16]      13,856\n",
      "├─MaxPool3d: 1-4                         [64, 32, 8, 8, 8]         --\n",
      "├─Conv3d: 1-5                            [64, 64, 8, 8, 8]         55,360\n",
      "├─MaxPool3d: 1-6                         [64, 64, 4, 4, 4]         --\n",
      "├─Linear: 1-7                            [64, 128]                 524,416\n",
      "├─Linear: 1-8                            [64, 10]                  1,290\n",
      "==========================================================================================\n",
      "Total params: 595,370\n",
      "Trainable params: 595,370\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 6.42\n",
      "==========================================================================================\n",
      "Input size (MB): 8.39\n",
      "Forward/backward pass size (MB): 352.39\n",
      "Params size (MB): 2.38\n",
      "Estimated Total Size (MB): 363.16\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "model = Simple3DCNN(num_classes=num_classes).to(device)\n",
    "print(summary(model, input_size=(batch_size, 1, grid_size, grid_size, grid_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_distribution = np.zeros(num_classes)\n",
    "test_class_distribution = np.zeros(num_classes)\n",
    "for label in train_dataset.labels:\n",
    "    train_class_distribution[label] += 1\n",
    "\n",
    "for label in test_dataset.labels:\n",
    "    test_class_distribution[label] += 1\n",
    "\n",
    "\n",
    "weights = np.sum(train_class_distribution) / train_class_distribution\n",
    "weights /= np.sum(weights)\n",
    "weights = torch.tensor(weights, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "#################\n",
      "# EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 5-dimensional input for 5-dimensional weight [32, 1, 3, 3, 3], but got 4-dimensional input of size [64, 32, 32, 32] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3a9620aa4243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/3dclassifier/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    584\u001b[0m             )\n\u001b[1;32m    585\u001b[0m         return F.conv3d(\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         )\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 5-dimensional input for 5-dimensional weight [32, 1, 3, 3, 3], but got 4-dimensional input of size [64, 32, 32, 32] instead"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Define your model, optimizer, and loss function\n",
    "loss_fn = nn.CrossEntropyLoss() # weight=weights\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3) # add weight_decay = 1e-4\n",
    "\n",
    "# Define the number of epochs and initialize logs\n",
    "num_epochs = 20\n",
    "train_loss_log = []\n",
    "val_loss_log = []\n",
    "best_val = np.inf\n",
    "start_epoch = 0\n",
    "\n",
    "# Check if there's a saved checkpoint\n",
    "checkpoint_path = \"checkpoint.pt\"\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    opt.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    train_loss_log = checkpoint[\"train_loss_log\"]\n",
    "    val_loss_log = checkpoint[\"val_loss_log\"]\n",
    "    best_val = checkpoint[\"best_val\"]\n",
    "    print(f\"Resuming from epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "for epoch_num in range(start_epoch, num_epochs):\n",
    "    print(\"#################\")\n",
    "    print(f\"# EPOCH {epoch_num}\")\n",
    "\n",
    "    ### TRAIN\n",
    "    model.train()  # Training mode (e.g. enable dropout, batchnorm updates,...)\n",
    "    train_losses = []\n",
    "    iterator = tqdm(train_dataloader)\n",
    "    for batch_x, batch_y in iterator:\n",
    "        # Move data to device\n",
    "        batch_x, batch_y  = batch_x.to(device), batch_y.to(device)\n",
    "        opt.zero_grad()\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(batch_x)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(out, batch_y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        opt.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        iterator.set_description(f\"Train loss: {round(loss.item(), 2)}\")\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    train_loss_log.append(avg_train_loss)\n",
    "\n",
    "    ### VALIDATION\n",
    "    model.eval()  # Evaluation mode (e.g. disable dropout, batchnorm,...)\n",
    "    val_losses = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for batch_x, batch_y in tqdm(test_dataloader):\n",
    "            # Move data to device\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = model(batch_x)\n",
    "\n",
    "            val_losses.append(loss_fn(out, batch_y).item())\n",
    "\n",
    "            _, predicted = torch.max(out, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    val_loss_log.append(avg_val_loss)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(\n",
    "        f\"Average validation loss: {round(avg_val_loss,2)}\\tValidation accuracy: {round(val_acc,2)}\"\n",
    "    )\n",
    "\n",
    "    # Save the model and optimizer state at each epoch\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch_num,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": opt.state_dict(),\n",
    "            \"train_loss_log\": train_loss_log,\n",
    "            \"val_loss_log\": val_loss_log,\n",
    "            \"best_val\": best_val,\n",
    "        },\n",
    "        checkpoint_path,\n",
    "    )\n",
    "\n",
    "    if avg_val_loss < best_val:\n",
    "        print(\"Update model!!!\")\n",
    "        torch.save(model.state_dict(), f\"best_model_{avg_val_loss}.pt\")\n",
    "        best_val = avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.to(device)\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Lists to store predictions and ground truth labels\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "iterator = tqdm(test_dataloader)\n",
    "for inputs, targets in iterator:\n",
    "    # Move data to device\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    # Convert outputs to predicted labels\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Append to lists\n",
    "    all_predictions.extend(predicted.cpu().numpy())\n",
    "    all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = accuracy_score(all_targets, all_predictions)\n",
    "print(f\"Overall Accuracy: {overall_accuracy}\")\n",
    "\n",
    "# Calculate accuracy per class\n",
    "class_names = [train_dataset.class_map.get(key) for key in range(num_classes)]\n",
    "class_report = classification_report(\n",
    "    all_targets, all_predictions, target_names=class_names\n",
    ")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Print numerical values in each cell of the matrix\n",
    "fmt = \"d\"\n",
    "thresh = cm.max() / 2.0\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(\n",
    "        j,\n",
    "        i,\n",
    "        format(cm[i, j], fmt),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose random samples\n",
    "num_samples = 5  # Number of random samples to predict\n",
    "random_indices = random.sample(range(len(test_dataset)), num_samples)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    # Get a random sample from the test set\n",
    "    sample, target = test_dataset[idx]\n",
    "    sample = sample.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    # Predict with the model\n",
    "    with torch.no_grad():\n",
    "        output = model(sample)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    # Convert predicted and target labels to numpy if needed\n",
    "    predicted_label = predicted.item()\n",
    "    true_label = target.item()  # Assuming target is a scalar label\n",
    "\n",
    "    # Plot the voxel grid\n",
    "    sample_np = (\n",
    "        sample.cpu().squeeze().numpy()\n",
    "    )  # Move sample to CPU and convert to numpy\n",
    "    ax = fig.add_subplot(1, num_samples, i + 1, projection=\"3d\")\n",
    "\n",
    "    # Voxel plot\n",
    "    sample_np = (sample_np + 1) / 2\n",
    "    ax.voxels(sample_np, edgecolor=\"k\")\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Pred: {train_dataset.class_map.get(predicted_label)}, True: {train_dataset.class_map.get(true_label)}\"\n",
    "    )\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.set_xlim(0, sample_np.shape[0])\n",
    "    ax.set_ylim(0, sample_np.shape[1])\n",
    "    ax.set_zlim(0, sample_np.shape[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class names from the dataset\n",
    "class_names = [train_dataset.class_map[i] for i in range(10)]\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, tight_layout=True, figsize=(10, 8))\n",
    "\n",
    "# Plot training class distribution\n",
    "axs[0].bar(range(10), train_class_distribution, color=\"skyblue\")\n",
    "axs[0].set_xticks(range(num_classes))\n",
    "axs[0].set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "axs[0].set_title(\"Training Class Distribution\")\n",
    "axs[0].set_ylabel(\"Number of Samples\")\n",
    "\n",
    "# Plot test class distribution\n",
    "axs[1].bar(range(num_classes), test_class_distribution, color=\"salmon\")\n",
    "axs[1].set_xticks(range(num_classes))\n",
    "axs[1].set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "axs[1].set_title(\"Test Class Distribution\")\n",
    "axs[1].set_ylabel(\"Number of Samples\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
